{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Layer KD Using T.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNY1xuB4zd1PKfGfcvn300j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea8e877f121a4c6d843fbe7a3c2044d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fc50590433f43a693aa98f7944e48f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61b5a1755c164971a6042fd949cec5b1",
              "IPY_MODEL_52d9f4807cd0472e965223a714e226ad",
              "IPY_MODEL_047e8a2ac4d8490fa6358e8a2f5172d4"
            ]
          }
        },
        "2fc50590433f43a693aa98f7944e48f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61b5a1755c164971a6042fd949cec5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f400e1fcda54580b3816c12aa5ca980",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5504f5524af948aca94d39d01405c7c6"
          }
        },
        "52d9f4807cd0472e965223a714e226ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bc8c4a619f2347a4b72447afba8d0c92",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_328beaea5aca460e99604cb27d705f91"
          }
        },
        "047e8a2ac4d8490fa6358e8a2f5172d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45ac369a4f4e43acb6d85e1f5f35b9ee",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 43842091.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ef2e7b48bbd40ada1496b4afcbe68b7"
          }
        },
        "8f400e1fcda54580b3816c12aa5ca980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5504f5524af948aca94d39d01405c7c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc8c4a619f2347a4b72447afba8d0c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "328beaea5aca460e99604cb27d705f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45ac369a4f4e43acb6d85e1f5f35b9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ef2e7b48bbd40ada1496b4afcbe68b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuBly/Knowledge_Distillation/blob/main/CNN_Layer_KD_Using_T.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOTxffaVyocz"
      },
      "source": [
        "이번 주차에는 위와 같은 과정을 적용시켜보고자 한다.\n",
        "\n",
        "1. BaseLine CNN 2 Layer \n",
        "2. Teacher model CNN 10 Layer\n",
        "3. DataSet:cifar10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjlJojxCWg2M"
      },
      "source": [
        "# **필요한 라이브러리를 import**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvW14IdP3Yms"
      },
      "source": [
        "import Library For Create CNN Layer model, Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NwNpk5qFq_e"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as torch_models\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdChl3dEF_9p"
      },
      "source": [
        "Import Library For Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rcO_G_xGDZ_"
      },
      "source": [
        "import os\n",
        "import copy\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kURabIgfGEfh"
      },
      "source": [
        "Import Library For Display Chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tGIBNDPGHQW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYuyOVfuGghp"
      },
      "source": [
        "Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZwnl8yNGhmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "ea8e877f121a4c6d843fbe7a3c2044d5",
            "2fc50590433f43a693aa98f7944e48f4",
            "61b5a1755c164971a6042fd949cec5b1",
            "52d9f4807cd0472e965223a714e226ad",
            "047e8a2ac4d8490fa6358e8a2f5172d4",
            "8f400e1fcda54580b3816c12aa5ca980",
            "5504f5524af948aca94d39d01405c7c6",
            "bc8c4a619f2347a4b72447afba8d0c92",
            "328beaea5aca460e99604cb27d705f91",
            "45ac369a4f4e43acb6d85e1f5f35b9ee",
            "2ef2e7b48bbd40ada1496b4afcbe68b7"
          ]
        },
        "outputId": "f1457956-9b8c-400d-ace8-ddccdb86110c"
      },
      "source": [
        "dataset_dir='./data'\n",
        "batch_size=128\n",
        "normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
        "simple_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
        "\n",
        "train_transform = simple_transform\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=dataset_dir, train=True,\n",
        "download=True, transform=train_transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=dataset_dir, train=False,\n",
        "download=True, transform=simple_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "pin_memory=True, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "pin_memory=True, shuffle=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea8e877f121a4c6d843fbe7a3c2044d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3AJFsCAIhjq"
      },
      "source": [
        "Teacher, Student Layer model 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmWUH-trFZ6A"
      },
      "source": [
        "class ConvNetMaker(nn.Module):\n",
        "\t\"\"\"\n",
        "\tCreates a simple (plane) convolutional neural network\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, layers):\n",
        "\t\t\"\"\"\n",
        "\t\tMakes a cnn using the provided list of layers specification\n",
        "\t\tThe details of this list is available in the paper\n",
        "\t\t:param layers: a list of strings, representing layers like [\"CB32\", \"CB32\", \"FC10\"]\n",
        "\t\t\"\"\"\n",
        "\t\tsuper(ConvNetMaker, self).__init__()\n",
        "\t\tself.conv_layers = []\n",
        "\t\tself.fc_layers = []\n",
        "\t\th, w, d = 32, 32, 3\n",
        "\t\tprevious_layer_filter_count = 3\n",
        "\t\tprevious_layer_size = h * w * d\n",
        "\t\tnum_fc_layers_remained = len([1 for l in layers if l.startswith('FC')])\n",
        "\t\tfor layer in layers:\n",
        "\t\t\tif layer.startswith('Conv'):\n",
        "\t\t\t\tfilter_count = int(layer[4:])\n",
        "\t\t\t\tself.conv_layers += [nn.Conv2d(previous_layer_filter_count, filter_count, kernel_size=3, padding=1),\n",
        "\t\t\t\t\t\t\t\t\t nn.BatchNorm2d(filter_count), nn.ReLU(inplace=True)]\n",
        "\t\t\t\tprevious_layer_filter_count = filter_count\n",
        "\t\t\t\td = filter_count\n",
        "\t\t\t\tprevious_layer_size = h * w * d\n",
        "\t\t\telif layer.startswith('MaxPool'):\n",
        "\t\t\t\tself.conv_layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "\t\t\t\th, w = int(h / 2.0), int(w / 2.0)\n",
        "\t\t\t\tprevious_layer_size = h * w * d\n",
        "\t\t\telif layer.startswith('FC'):\n",
        "\t\t\t\tnum_fc_layers_remained -= 1\n",
        "\t\t\t\tcurrent_layer_size = int(layer[2:])\n",
        "\t\t\t\tif num_fc_layers_remained == 0:\n",
        "\t\t\t\t\tself.fc_layers += [nn.Linear(previous_layer_size, current_layer_size)]\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tself.fc_layers += [nn.Linear(previous_layer_size, current_layer_size), nn.ReLU(inplace=True)]\n",
        "\t\t\t\tprevious_layer_size = current_layer_size\n",
        "\t\t\n",
        "\t\tconv_layers = self.conv_layers\n",
        "\t\tfc_layers = self.fc_layers\n",
        "\t\tself.conv_layers = nn.Sequential(*conv_layers)\n",
        "\t\tself.fc_layers = nn.Sequential(*fc_layers)\n",
        "\t\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.conv_layers(x)\n",
        "\t\tx = x.view(x.size(0), -1)\n",
        "\t\tx = self.fc_layers(x)\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "\n",
        "def plane2():\n",
        "    return ConvNetMaker(['Conv16', 'MaxPool', 'Conv16', 'MaxPool', 'FC10'])\n",
        "\t\t\n",
        "def plane10():\n",
        "    return ConvNetMaker(['Conv32', 'Conv32', 'MaxPool', 'Conv64', 'Conv64', 'MaxPool', 'Conv128', 'Conv128', 'MaxPool',\n",
        "\t\t   'Conv256', 'Conv256', 'Conv256', 'Conv256' , 'MaxPool', 'FC128' ,'FC10'])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAaAc3iIbFJk"
      },
      "source": [
        "KD를 미적용한 Student Model의 학습_BaseLine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-byK8k6yeZq5",
        "outputId": "088b500d-710f-4002-81ea-8de16a79f4af"
      },
      "source": [
        "# check\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = plane2().to(device)\n",
        "x = torch.randn(3,3,32,32).to(device)\n",
        "output = model(x)\n",
        "print(output.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0DbpwlUcTxT"
      },
      "source": [
        "가중치 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XvuceYacUGw"
      },
      "source": [
        "# weight initialization\n",
        "def initialize_weights(model):\n",
        "    classname = model.__class__.__name__\n",
        "    # fc layer\n",
        "    if classname.find('Linear') != -1:\n",
        "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)\n",
        "    # batchnorm\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgkMu9-Weelp"
      },
      "source": [
        "initialize_weights(model)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk7qe8P2c0Xj"
      },
      "source": [
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer\n",
        "opt = optim.Adam(model.parameters())\n",
        "\n",
        "# lr scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCX4deU5c4c0"
      },
      "source": [
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']\n",
        "def metric_batch(output, target):\n",
        "    pred = output.argmax(1, keepdim=True)\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss_b = loss_func(output, target)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "    \n",
        "    return loss_b.item(), metric_b\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        output = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        running_loss += loss_b\n",
        "        \n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    loss = running_loss / len_data\n",
        "    metric = running_metric / len_data\n",
        "    return loss, metric    \n",
        "def train_val(model, params):\n",
        "    num_epochs=params['num_epochs']\n",
        "    loss_func=params['loss_func']\n",
        "    opt=params['optimizer']\n",
        "    train_dl=params['train_dl']\n",
        "    val_dl=params['val_dl']\n",
        "    sanity_check=params['sanity_check']\n",
        "    lr_scheduler=params['lr_scheduler']\n",
        "    path2weights=params['path2weights']\n",
        "\n",
        "    loss_history = {'train': [], 'val': []}\n",
        "    metric_history = {'train': [], 'val': []}\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "        loss_history['val'].append(val_loss)\n",
        "        metric_history['val'].append(val_metric)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights!')\n",
        "\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "        print('-'*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FxFvRdubtom"
      },
      "source": [
        "# set hyper parameters\n",
        "params_train = {\n",
        "    'num_epochs':20,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':trainloader,\n",
        "    'val_dl':testloader,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDyRYEbJbO5X",
        "outputId": "d825aa67-b156-42d7-979e-94cecc8faca5"
      },
      "source": [
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.010843, val loss: 0.009323, accuracy: 58.36, time: 0.3202 min\n",
            "----------\n",
            "Epoch 1/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.008644, val loss: 0.008495, accuracy: 62.47, time: 0.6393 min\n",
            "----------\n",
            "Epoch 2/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.007872, val loss: 0.008445, accuracy: 63.23, time: 0.9581 min\n",
            "----------\n",
            "Epoch 3/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.007471, val loss: 0.007913, accuracy: 64.85, time: 1.2753 min\n",
            "----------\n",
            "Epoch 4/19, current lr= 0.001\n",
            "train loss: 0.007174, val loss: 0.007983, accuracy: 65.46, time: 1.5910 min\n",
            "----------\n",
            "Epoch 5/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.006947, val loss: 0.007837, accuracy: 66.22, time: 1.9093 min\n",
            "----------\n",
            "Epoch 6/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.006779, val loss: 0.007568, accuracy: 66.96, time: 2.2264 min\n",
            "----------\n",
            "Epoch 7/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.006638, val loss: 0.007388, accuracy: 67.92, time: 2.5439 min\n",
            "----------\n",
            "Epoch 8/19, current lr= 0.001\n",
            "train loss: 0.006546, val loss: 0.007448, accuracy: 67.38, time: 2.8593 min\n",
            "----------\n",
            "Epoch 9/19, current lr= 0.001\n",
            "train loss: 0.006412, val loss: 0.007504, accuracy: 67.47, time: 3.1753 min\n",
            "----------\n",
            "Epoch 10/19, current lr= 0.001\n",
            "train loss: 0.006334, val loss: 0.008066, accuracy: 66.06, time: 3.4935 min\n",
            "----------\n",
            "Epoch 11/19, current lr= 0.001\n",
            "train loss: 0.006273, val loss: 0.007438, accuracy: 68.15, time: 3.8124 min\n",
            "----------\n",
            "Epoch 12/19, current lr= 0.001\n",
            "train loss: 0.006191, val loss: 0.007483, accuracy: 67.86, time: 4.1301 min\n",
            "----------\n",
            "Epoch 13/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.006114, val loss: 0.007371, accuracy: 68.00, time: 4.4464 min\n",
            "----------\n",
            "Epoch 14/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.006056, val loss: 0.007265, accuracy: 68.98, time: 4.7642 min\n",
            "----------\n",
            "Epoch 15/19, current lr= 0.001\n",
            "train loss: 0.006017, val loss: 0.007781, accuracy: 66.50, time: 5.0809 min\n",
            "----------\n",
            "Epoch 16/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.005947, val loss: 0.007227, accuracy: 68.94, time: 5.4006 min\n",
            "----------\n",
            "Epoch 17/19, current lr= 0.001\n",
            "train loss: 0.005888, val loss: 0.007254, accuracy: 68.83, time: 5.7183 min\n",
            "----------\n",
            "Epoch 18/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.005848, val loss: 0.007148, accuracy: 69.51, time: 6.0362 min\n",
            "----------\n",
            "Epoch 19/19, current lr= 0.001\n",
            "train loss: 0.005830, val loss: 0.007321, accuracy: 68.71, time: 6.3560 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy_vddrXRAhw"
      },
      "source": [
        "Teacher model 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo_7z9J6Izw2",
        "outputId": "05d6145a-6c44-42e5-9412-ffa17b360236"
      },
      "source": [
        "# check\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "teacher = plane10().to(device)\n",
        "x = torch.randn(3,3,32,32).to(device)\n",
        "output = teacher(x)\n",
        "print(output.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "958bd-yPIzVE"
      },
      "source": [
        "가중치 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBPuKe87Q6u_"
      },
      "source": [
        "teacher.apply(initialize_weights);"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NriBhxZYRjcX"
      },
      "source": [
        "# optimizer\n",
        "opt = optim.Adam(teacher.parameters())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfNWhiOaRSNJ"
      },
      "source": [
        "하이퍼 파라미터 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfmr7EK9RP6T"
      },
      "source": [
        "params_train = {\n",
        "    'num_epochs':20,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':trainloader,\n",
        "    'val_dl':testloader,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/teacher_weights.pt',\n",
        "}\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TES3UekoRw3m",
        "outputId": "d2216a09-19b3-4576-e826-dd97ac962700"
      },
      "source": [
        "teacher, loss_hist, metric_hist = train_val(teacher, params_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.010510, val loss: 0.009123, accuracy: 60.60, time: 0.7736 min\n",
            "----------\n",
            "Epoch 1/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.006501, val loss: 0.007318, accuracy: 68.40, time: 1.5451 min\n",
            "----------\n",
            "Epoch 2/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.005022, val loss: 0.005442, accuracy: 76.66, time: 2.3170 min\n",
            "----------\n",
            "Epoch 3/19, current lr= 0.001\n",
            "train loss: 0.004085, val loss: 0.005698, accuracy: 76.32, time: 3.0872 min\n",
            "----------\n",
            "Epoch 4/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.003418, val loss: 0.004892, accuracy: 79.67, time: 3.8558 min\n",
            "----------\n",
            "Epoch 5/19, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.002893, val loss: 0.004853, accuracy: 81.12, time: 4.6227 min\n",
            "----------\n",
            "Epoch 6/19, current lr= 0.001\n",
            "train loss: 0.002417, val loss: 0.005442, accuracy: 78.43, time: 5.3908 min\n",
            "----------\n",
            "Epoch 7/19, current lr= 0.001\n",
            "train loss: 0.002050, val loss: 0.004930, accuracy: 81.55, time: 6.1589 min\n",
            "----------\n",
            "Epoch 8/19, current lr= 0.001\n",
            "train loss: 0.001658, val loss: 0.005784, accuracy: 79.51, time: 6.9249 min\n",
            "----------\n",
            "Epoch 9/19, current lr= 0.001\n",
            "train loss: 0.001379, val loss: 0.005819, accuracy: 81.24, time: 7.6887 min\n",
            "----------\n",
            "Epoch 10/19, current lr= 0.001\n",
            "train loss: 0.001178, val loss: 0.005015, accuracy: 82.66, time: 8.4564 min\n",
            "----------\n",
            "Epoch 11/19, current lr= 0.001\n",
            "train loss: 0.000971, val loss: 0.005608, accuracy: 81.77, time: 9.2272 min\n",
            "----------\n",
            "Epoch 12/19, current lr= 0.001\n",
            "train loss: 0.000912, val loss: 0.005717, accuracy: 81.84, time: 9.9937 min\n",
            "----------\n",
            "Epoch 13/19, current lr= 0.001\n",
            "train loss: 0.000793, val loss: 0.005781, accuracy: 82.70, time: 10.7629 min\n",
            "----------\n",
            "Epoch 14/19, current lr= 0.001\n",
            "train loss: 0.000644, val loss: 0.007009, accuracy: 80.57, time: 11.5342 min\n",
            "----------\n",
            "Epoch 15/19, current lr= 0.001\n",
            "train loss: 0.000588, val loss: 0.006973, accuracy: 81.50, time: 12.2982 min\n",
            "----------\n",
            "Epoch 16/19, current lr= 0.001\n",
            "train loss: 0.000592, val loss: 0.005947, accuracy: 83.59, time: 13.0627 min\n",
            "----------\n",
            "Epoch 17/19, current lr= 0.001\n",
            "train loss: 0.000497, val loss: 0.006249, accuracy: 83.52, time: 13.8284 min\n",
            "----------\n",
            "Epoch 18/19, current lr= 0.001\n",
            "train loss: 0.000436, val loss: 0.006199, accuracy: 83.20, time: 14.5949 min\n",
            "----------\n",
            "Epoch 19/19, current lr= 0.001\n",
            "train loss: 0.000462, val loss: 0.006406, accuracy: 81.83, time: 15.3620 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTF4W3eKWYtl"
      },
      "source": [
        "Student Model 학습."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm1UJJk0Wf2t",
        "outputId": "269b8227-4b1a-40f3-ceac-4510e4cb02c2"
      },
      "source": [
        "# check\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "student = plane2().to(device)\n",
        "x = torch.randn(3,3,32,32).to(device)\n",
        "output = teacher(x)\n",
        "print(output.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tir-buHDWif7"
      },
      "source": [
        "가중치 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahtYcPYPWjwh"
      },
      "source": [
        "student.apply(initialize_weights);"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThlpAycBWzEg"
      },
      "source": [
        "Teacher 학습을 통해 얻은 Weight값들을 load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFMIqNBiW3OL"
      },
      "source": [
        "teacher = plane10().to(device)\n",
        "# load weight\n",
        "teacher.load_state_dict(torch.load('/content/models/teacher_weights.pt'))\n",
        "student = plane2().to(device)\n",
        "\n",
        "# optimizer\n",
        "opt = optim.Adam(student.parameters())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO292MoJXEAE"
      },
      "source": [
        "KD함수 선언 및 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX2CKf1UXGOT"
      },
      "source": [
        "# knowledge distillation loss\n",
        "def distillation(y, labels, teacher_scores, T, alpha):\n",
        "    # distillation loss + classification loss\n",
        "    # y: student\n",
        "    # labels: hard label\n",
        "    # teacher_scores: soft label\n",
        "    return nn.KLDivLoss()(F.log_softmax(y/T), F.softmax(teacher_scores/T)) * (T*T * 2.0 + alpha) + F.cross_entropy(y,labels) * (1.-alpha)\n",
        "\n",
        "# val loss\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvi2ncDaXJgB"
      },
      "source": [
        "def distill_loss_batch(output, target, teacher_output, loss_fn=distillation, opt=opt):\n",
        "    loss_b = loss_fn(output, target, teacher_output, T=5.0, alpha=0.7)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss_b.item(), metric_b"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvDNaacaXQBZ"
      },
      "source": [
        "20epoch로 학습결과 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apehYMMGXT54",
        "outputId": "a6671e3e-f431-4336-e598-c2880615371f"
      },
      "source": [
        "num_epochs= 20\n",
        "\n",
        "loss_history = {'train': [], 'val': []}\n",
        "metric_history = {'train': [], 'val': []}\n",
        "\n",
        "best_loss = float('inf')\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "    # train\n",
        "    student.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(trainloader.dataset)\n",
        "\n",
        "    for xb, yb in trainloader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        output = student(xb)\n",
        "        teacher_output = teacher(xb).detach()\n",
        "        loss_b, metric_b = distill_loss_batch(output, yb, teacher_output, loss_fn=distillation, opt=opt)\n",
        "        running_loss += loss_b\n",
        "        running_metric_b = metric_b\n",
        "    train_loss = running_loss / len_data\n",
        "    train_metric = running_metric / len_data\n",
        "\n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # validation\n",
        "    student.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_metric = loss_epoch(student, loss_func, testloader)\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "\n",
        "    lr_scheduler.step(val_loss)\n",
        "\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19, current lr= 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2748: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.005569, val loss: 0.007316, accuracy: 69.08, time: 0.5263 min\n",
            "----------\n",
            "Epoch 1/19, current lr= 0.001\n",
            "train loss: 0.005526, val loss: 0.007403, accuracy: 69.03, time: 1.0499 min\n",
            "----------\n",
            "Epoch 2/19, current lr= 0.001\n",
            "train loss: 0.005487, val loss: 0.007314, accuracy: 69.55, time: 1.5729 min\n",
            "----------\n",
            "Epoch 3/19, current lr= 0.001\n",
            "train loss: 0.005465, val loss: 0.007205, accuracy: 69.86, time: 2.0955 min\n",
            "----------\n",
            "Epoch 4/19, current lr= 0.001\n",
            "train loss: 0.005445, val loss: 0.007231, accuracy: 69.22, time: 2.6211 min\n",
            "----------\n",
            "Epoch 5/19, current lr= 0.001\n",
            "train loss: 0.005406, val loss: 0.007055, accuracy: 70.30, time: 3.1446 min\n",
            "----------\n",
            "Epoch 6/19, current lr= 0.001\n",
            "train loss: 0.005388, val loss: 0.007339, accuracy: 69.26, time: 3.6668 min\n",
            "----------\n",
            "Epoch 7/19, current lr= 0.001\n",
            "train loss: 0.005366, val loss: 0.007072, accuracy: 70.52, time: 4.1879 min\n",
            "----------\n",
            "Epoch 8/19, current lr= 0.001\n",
            "train loss: 0.005331, val loss: 0.007101, accuracy: 70.34, time: 4.7098 min\n",
            "----------\n",
            "Epoch 9/19, current lr= 0.001\n",
            "train loss: 0.005355, val loss: 0.007024, accuracy: 70.22, time: 5.2320 min\n",
            "----------\n",
            "Epoch 10/19, current lr= 0.001\n",
            "train loss: 0.005312, val loss: 0.006949, accuracy: 70.43, time: 5.7529 min\n",
            "----------\n",
            "Epoch 11/19, current lr= 0.001\n",
            "train loss: 0.005310, val loss: 0.007314, accuracy: 69.65, time: 6.2746 min\n",
            "----------\n",
            "Epoch 12/19, current lr= 0.001\n",
            "train loss: 0.005275, val loss: 0.007126, accuracy: 70.26, time: 6.7958 min\n",
            "----------\n",
            "Epoch 13/19, current lr= 0.001\n",
            "train loss: 0.005276, val loss: 0.007020, accuracy: 70.44, time: 7.3182 min\n",
            "----------\n",
            "Epoch 14/19, current lr= 0.001\n",
            "train loss: 0.005264, val loss: 0.007165, accuracy: 69.51, time: 7.8405 min\n",
            "----------\n",
            "Epoch 15/19, current lr= 0.001\n",
            "train loss: 0.005246, val loss: 0.007023, accuracy: 70.59, time: 8.3630 min\n",
            "----------\n",
            "Epoch 16/19, current lr= 0.001\n",
            "train loss: 0.005234, val loss: 0.007113, accuracy: 69.92, time: 8.8840 min\n",
            "----------\n",
            "Epoch 17/19, current lr= 0.001\n",
            "train loss: 0.005200, val loss: 0.006996, accuracy: 70.75, time: 9.4074 min\n",
            "----------\n",
            "Epoch 18/19, current lr= 0.001\n",
            "train loss: 0.005199, val loss: 0.007011, accuracy: 70.75, time: 9.9275 min\n",
            "----------\n",
            "Epoch 19/19, current lr= 0.001\n",
            "train loss: 0.005191, val loss: 0.007027, accuracy: 70.30, time: 10.4489 min\n",
            "----------\n"
          ]
        }
      ]
    }
  ]
}