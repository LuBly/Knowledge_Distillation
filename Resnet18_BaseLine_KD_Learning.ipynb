{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet18_BaseLine_KD_Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvGqH0OMWyBhxjGRxKX35l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ebd88c1fb1e04eca88cb805bb8122a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f7c13a9d77743ff8852b39cfbc07fea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20b85775ecbd46ac90cf109fd4fcd6fa",
              "IPY_MODEL_ae3a59c2a9904e5dab6f3c69cd70908b",
              "IPY_MODEL_c5ac36f0a9d14848993f05a219559fd0"
            ]
          }
        },
        "0f7c13a9d77743ff8852b39cfbc07fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20b85775ecbd46ac90cf109fd4fcd6fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d4405496b03e405286d6ee6a769899e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f519355fe5e4e57bec313fd0e308585"
          }
        },
        "ae3a59c2a9904e5dab6f3c69cd70908b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2b2f3bc1c2b4eb6824161c04203c866",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ecf3082555b4c2a8aecab10bc68e30c"
          }
        },
        "c5ac36f0a9d14848993f05a219559fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c008cf1c0bbc48878e32350693c82c67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:12&lt;00:00, 16772744.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d92c5f852baa439c9e4c65fb8455e9d6"
          }
        },
        "d4405496b03e405286d6ee6a769899e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f519355fe5e4e57bec313fd0e308585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2b2f3bc1c2b4eb6824161c04203c866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ecf3082555b4c2a8aecab10bc68e30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c008cf1c0bbc48878e32350693c82c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d92c5f852baa439c9e4c65fb8455e9d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuBly/Knowledge_Distillation/blob/main/Resnet18_BaseLine_KD_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvRWbLYKZr2X"
      },
      "source": [
        "import Library For Create Resnet Layer model& Data Load\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kLM_zFF-3kT"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as torch_models\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kQ9VttGZ3yc"
      },
      "source": [
        "Import Library For Training and Display Chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oADLncwWZzN-"
      },
      "source": [
        "import os\n",
        "import copy\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvvZBbbkaBuu"
      },
      "source": [
        "Resnet Model 생성\n",
        "1. Residual block 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlsvjJckaDt_"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정합니다.\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
        "        )\n",
        "\n",
        "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # projection mapping using 1x1conv\n",
        "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.residual_function(x) + self.shortcut(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.residual_function = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
        "        )\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
        "            )\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.residual_function(x) + self.shortcut(x)\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYiyuWPI4zpJ"
      },
      "source": [
        "2. Resnet Model 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbqZIbKT44k0"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_block, num_classes=10, init_weights=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels=64\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        # weights inittialization\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_channels, out_channels, stride))\n",
        "            self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self,x):\n",
        "        output = self.conv1(x)\n",
        "        output = self.conv2_x(output)\n",
        "        x = self.conv3_x(output)\n",
        "        x = self.conv4_x(x)\n",
        "        x = self.conv5_x(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    # define weight initialization function\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def resnet18():\n",
        "    return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def resnet50():\n",
        "    return ResNet(BottleNeck, [3,4,6,3])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzKbMy075HT-"
      },
      "source": [
        "Model check_BaseLine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOncralk5JNc",
        "outputId": "828689b8-72e4-46f8-895a-766092a96d20"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_S = resnet18().to(device)\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model_S(x)\n",
        "print(output.size())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J384NeJe54Te",
        "outputId": "80e242db-3a06-413a-a6ab-b3c9080c2bbf"
      },
      "source": [
        "summary(model_S, (3, 224, 224), device=device.type)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
            "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
            "             ReLU-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
            "             ReLU-17           [-1, 64, 56, 56]               0\n",
            "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
            "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
            "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
            "             ReLU-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
            "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
            "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
            "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
            "             ReLU-30          [-1, 128, 28, 28]               0\n",
            "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
            "             ReLU-33          [-1, 128, 28, 28]               0\n",
            "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
            "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
            "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
            "             ReLU-37          [-1, 256, 14, 14]               0\n",
            "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
            "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
            "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
            "             ReLU-42          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
            "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
            "             ReLU-46          [-1, 256, 14, 14]               0\n",
            "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
            "             ReLU-49          [-1, 256, 14, 14]               0\n",
            "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
            "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-53            [-1, 512, 7, 7]               0\n",
            "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
            "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-58            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
            "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-62            [-1, 512, 7, 7]               0\n",
            "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
            "             ReLU-65            [-1, 512, 7, 7]               0\n",
            "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,181,642\n",
            "Trainable params: 11,181,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 62.79\n",
            "Params size (MB): 42.65\n",
            "Estimated Total Size (MB): 106.01\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd2iObvHAARD"
      },
      "source": [
        "가중치 초기화 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWcJqy-G__H9"
      },
      "source": [
        "# weight initialization\n",
        "def initialize_weights(model):\n",
        "    classname = model.__class__.__name__\n",
        "    # fc layer\n",
        "    if classname.find('Linear') != -1:\n",
        "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)\n",
        "    # batchnorm\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(model.bias.data, 0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uebu1pFB6HNA"
      },
      "source": [
        "Data Load\n",
        "\n",
        "1. Batch size 128\n",
        "2. Batch size 64\n",
        "3. Batch size 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "ebd88c1fb1e04eca88cb805bb8122a86",
            "0f7c13a9d77743ff8852b39cfbc07fea",
            "20b85775ecbd46ac90cf109fd4fcd6fa",
            "ae3a59c2a9904e5dab6f3c69cd70908b",
            "c5ac36f0a9d14848993f05a219559fd0",
            "d4405496b03e405286d6ee6a769899e9",
            "1f519355fe5e4e57bec313fd0e308585",
            "c2b2f3bc1c2b4eb6824161c04203c866",
            "0ecf3082555b4c2a8aecab10bc68e30c",
            "c008cf1c0bbc48878e32350693c82c67",
            "d92c5f852baa439c9e4c65fb8455e9d6"
          ]
        },
        "id": "CEnuAEEq6Vil",
        "outputId": "b46e429d-f86e-4a69-afe6-ab4657b7974c"
      },
      "source": [
        "dataset_dir='./data'\n",
        "batch_size=128\n",
        "normalize = transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
        "simple_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
        "\n",
        "train_transform = simple_transform\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root=dataset_dir, train=True,\n",
        "download=True, transform=train_transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root=dataset_dir, train=False,\n",
        "download=True, transform=simple_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "pin_memory=True, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "pin_memory=True, shuffle=False)\n",
        "\n",
        "  \n",
        "\n",
        "print(\"CIFAR10\")\n",
        "print(\"---\"*20)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebd88c1fb1e04eca88cb805bb8122a86",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "CIFAR10\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7uOnmEM61Ru"
      },
      "source": [
        "모델 학습 함수\n",
        "1. Learning Rate 0.01 \n",
        "2. Learning Rate 0.001\n",
        "3. Learning Rate 0.1\n",
        "->사실상 lr scheduler에 의해 조절된다. epoch가 늘어나면 해결되는 현상."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUGN4uP_79tI"
      },
      "source": [
        "Colab설정상 많은 epoch를 실행시킬 수 없으므로, patience를 낮춰 조절해본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts3bZsvg642n"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(model_S.parameters(), lr=0.01)\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELvoJgcx7ihU"
      },
      "source": [
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw77DOiM8Mcf"
      },
      "source": [
        "def metric_batch(output, target):\n",
        "    pred = output.argmax(1, keepdim=True)\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "\n",
        "# function to calculate loss per mini-batch\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss = loss_func(output, target)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss.item(), metric_b"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owb5WLJ18O6X"
      },
      "source": [
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        output = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        running_loss += loss_b\n",
        "        \n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "        \n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    loss = running_loss / len_data\n",
        "    metric = running_metric / len_data\n",
        "\n",
        "    return loss, metric"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvLDDkNs8TWN"
      },
      "source": [
        "def train_val(model, params):\n",
        "    num_epochs=params['num_epochs']\n",
        "    loss_func=params['loss_func']\n",
        "    opt=params['optimizer']\n",
        "    train_dl=params['train_dl']\n",
        "    val_dl=params['val_dl']\n",
        "    sanity_check=params['sanity_check']\n",
        "    lr_scheduler=params['lr_scheduler']\n",
        "    path2weights=params['path2weights']\n",
        "\n",
        "    loss_history = {'train': [], 'val': []}\n",
        "    metric_history = {'train': [], 'val': []}\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "        loss_history['val'].append(val_loss)\n",
        "        metric_history['val'].append(val_metric)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights!')\n",
        "\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "        print('-'*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7ooNACE8fRr"
      },
      "source": [
        "학습 parameter 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBSB7-D08eUT"
      },
      "source": [
        "params_train = {\n",
        "    'num_epochs':30,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':trainloader,\n",
        "    'val_dl':testloader,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# create the directory that stores weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9hWdF1z8mi1"
      },
      "source": [
        "Student(BaseLine) 학습 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8GTreY1_kgW"
      },
      "source": [
        "model_S.apply(initialize_weights);"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuspeBVz8lN2",
        "outputId": "c3d95de5-6cd0-487d-ac87-4be8c904e534"
      },
      "source": [
        "model_S, loss_hist, metric_hist = train_val(model_S, params_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.704045, val loss: 1.564995, accuracy: 47.08, time: 0.7370 min\n",
            "----------\n",
            "Epoch 1/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.180498, val loss: 1.164660, accuracy: 59.50, time: 1.4640 min\n",
            "----------\n",
            "Epoch 2/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.933651, val loss: 1.013273, accuracy: 65.44, time: 2.1889 min\n",
            "----------\n",
            "Epoch 3/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.788560, val loss: 0.851117, accuracy: 70.25, time: 2.9117 min\n",
            "----------\n",
            "Epoch 4/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.670398, val loss: 0.816886, accuracy: 72.20, time: 3.6313 min\n",
            "----------\n",
            "Epoch 5/29, current lr= 0.01\n",
            "train loss: 0.567505, val loss: 0.816904, accuracy: 73.15, time: 4.3510 min\n",
            "----------\n",
            "Epoch 6/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.485089, val loss: 0.801377, accuracy: 73.75, time: 5.0810 min\n",
            "----------\n",
            "Epoch 7/29, current lr= 0.01\n",
            "train loss: 0.398869, val loss: 0.844647, accuracy: 73.78, time: 5.8053 min\n",
            "----------\n",
            "Epoch 8/29, current lr= 0.01\n",
            "train loss: 0.321155, val loss: 0.890933, accuracy: 73.85, time: 6.5265 min\n",
            "----------\n",
            "Epoch 9/29, current lr= 0.01\n",
            "train loss: 0.261749, val loss: 0.990154, accuracy: 73.10, time: 7.2501 min\n",
            "----------\n",
            "Epoch 10/29, current lr= 0.01\n",
            "train loss: 0.215835, val loss: 0.969191, accuracy: 74.83, time: 7.9766 min\n",
            "----------\n",
            "Epoch 11/29, current lr= 0.01\n",
            "train loss: 0.173538, val loss: 1.076414, accuracy: 73.93, time: 8.6986 min\n",
            "----------\n",
            "Epoch 12/29, current lr= 0.01\n",
            "train loss: 0.148448, val loss: 1.046011, accuracy: 74.62, time: 9.4249 min\n",
            "----------\n",
            "Epoch 13/29, current lr= 0.01\n",
            "train loss: 0.131137, val loss: 1.067161, accuracy: 75.14, time: 10.1468 min\n",
            "----------\n",
            "Epoch 14/29, current lr= 0.01\n",
            "train loss: 0.109862, val loss: 1.093191, accuracy: 75.53, time: 10.8698 min\n",
            "----------\n",
            "Epoch 15/29, current lr= 0.01\n",
            "train loss: 0.103668, val loss: 1.183167, accuracy: 74.83, time: 11.5935 min\n",
            "----------\n",
            "Epoch 16/29, current lr= 0.01\n",
            "train loss: 0.097703, val loss: 1.231880, accuracy: 74.18, time: 12.3161 min\n",
            "----------\n",
            "Epoch 17/29, current lr= 0.01\n",
            "Loading best model weights!\n",
            "train loss: 0.085546, val loss: 1.294368, accuracy: 75.16, time: 13.0380 min\n",
            "----------\n",
            "Epoch 18/29, current lr= 0.001\n",
            "Copied best model weights!\n",
            "train loss: 0.228712, val loss: 0.794582, accuracy: 77.54, time: 13.7662 min\n",
            "----------\n",
            "Epoch 19/29, current lr= 0.001\n",
            "train loss: 0.134739, val loss: 0.921062, accuracy: 77.59, time: 14.4940 min\n",
            "----------\n",
            "Epoch 20/29, current lr= 0.001\n",
            "train loss: 0.082894, val loss: 1.047568, accuracy: 77.43, time: 15.2212 min\n",
            "----------\n",
            "Epoch 21/29, current lr= 0.001\n",
            "train loss: 0.048918, val loss: 1.176812, accuracy: 77.31, time: 15.9485 min\n",
            "----------\n",
            "Epoch 22/29, current lr= 0.001\n",
            "train loss: 0.029627, val loss: 1.327024, accuracy: 76.73, time: 16.6732 min\n",
            "----------\n",
            "Epoch 23/29, current lr= 0.001\n",
            "train loss: 0.020100, val loss: 1.509383, accuracy: 76.60, time: 17.4020 min\n",
            "----------\n",
            "Epoch 24/29, current lr= 0.001\n",
            "train loss: 0.017626, val loss: 1.509478, accuracy: 76.90, time: 18.1306 min\n",
            "----------\n",
            "Epoch 25/29, current lr= 0.001\n",
            "train loss: 0.013855, val loss: 1.623927, accuracy: 76.53, time: 18.8610 min\n",
            "----------\n",
            "Epoch 26/29, current lr= 0.001\n",
            "train loss: 0.010929, val loss: 1.725133, accuracy: 76.54, time: 19.5935 min\n",
            "----------\n",
            "Epoch 27/29, current lr= 0.001\n",
            "train loss: 0.013487, val loss: 1.723858, accuracy: 76.90, time: 20.3165 min\n",
            "----------\n",
            "Epoch 28/29, current lr= 0.001\n",
            "train loss: 0.013435, val loss: 1.692327, accuracy: 76.75, time: 21.0472 min\n",
            "----------\n",
            "Epoch 29/29, current lr= 0.001\n",
            "Loading best model weights!\n",
            "train loss: 0.010322, val loss: 1.814325, accuracy: 76.99, time: 21.7709 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8r-2EPV5qUQ"
      },
      "source": [
        "Model check_Teacher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1MEz7zv5vbj",
        "outputId": "fe6d1438-24f4-4a23-e4ce-356838e750aa"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_T = resnet50().to(device)\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model_T(x)\n",
        "print(output.size())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlLQhet856L7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edcd0d8-5596-497a-e6d8-0d37428ac4ac"
      },
      "source": [
        "summary(model_T, (3, 224, 224), device=device.type)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
            "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
            "              ReLU-7           [-1, 64, 56, 56]               0\n",
            "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
            "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
            "             ReLU-10           [-1, 64, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
            "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
            "             ReLU-15          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
            "             ReLU-19           [-1, 64, 56, 56]               0\n",
            "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
            "             ReLU-22           [-1, 64, 56, 56]               0\n",
            "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
            "             ReLU-25          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-26          [-1, 256, 56, 56]               0\n",
            "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
            "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
            "             ReLU-29           [-1, 64, 56, 56]               0\n",
            "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
            "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
            "             ReLU-32           [-1, 64, 56, 56]               0\n",
            "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
            "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
            "             ReLU-35          [-1, 256, 56, 56]               0\n",
            "       BottleNeck-36          [-1, 256, 56, 56]               0\n",
            "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
            "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
            "             ReLU-39          [-1, 128, 56, 56]               0\n",
            "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
            "             ReLU-42          [-1, 128, 28, 28]               0\n",
            "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
            "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-47          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-48          [-1, 512, 28, 28]               0\n",
            "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
            "             ReLU-51          [-1, 128, 28, 28]               0\n",
            "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
            "             ReLU-54          [-1, 128, 28, 28]               0\n",
            "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-57          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-58          [-1, 512, 28, 28]               0\n",
            "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
            "             ReLU-61          [-1, 128, 28, 28]               0\n",
            "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
            "             ReLU-64          [-1, 128, 28, 28]               0\n",
            "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-67          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-68          [-1, 512, 28, 28]               0\n",
            "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
            "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
            "             ReLU-71          [-1, 128, 28, 28]               0\n",
            "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
            "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
            "             ReLU-74          [-1, 128, 28, 28]               0\n",
            "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
            "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-77          [-1, 512, 28, 28]               0\n",
            "       BottleNeck-78          [-1, 512, 28, 28]               0\n",
            "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
            "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
            "             ReLU-81          [-1, 256, 28, 28]               0\n",
            "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
            "             ReLU-84          [-1, 256, 14, 14]               0\n",
            "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
            "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
            "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-89         [-1, 1024, 14, 14]               0\n",
            "       BottleNeck-90         [-1, 1024, 14, 14]               0\n",
            "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
            "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
            "             ReLU-93          [-1, 256, 14, 14]               0\n",
            "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
            "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
            "             ReLU-96          [-1, 256, 14, 14]               0\n",
            "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
            "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
            "             ReLU-99         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-100         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
            "            ReLU-103          [-1, 256, 14, 14]               0\n",
            "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
            "            ReLU-106          [-1, 256, 14, 14]               0\n",
            "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-109         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-110         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
            "            ReLU-113          [-1, 256, 14, 14]               0\n",
            "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
            "            ReLU-116          [-1, 256, 14, 14]               0\n",
            "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-119         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-120         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
            "            ReLU-123          [-1, 256, 14, 14]               0\n",
            "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
            "            ReLU-126          [-1, 256, 14, 14]               0\n",
            "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-129         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-130         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
            "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
            "            ReLU-133          [-1, 256, 14, 14]               0\n",
            "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
            "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
            "            ReLU-136          [-1, 256, 14, 14]               0\n",
            "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
            "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
            "            ReLU-139         [-1, 1024, 14, 14]               0\n",
            "      BottleNeck-140         [-1, 1024, 14, 14]               0\n",
            "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
            "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
            "            ReLU-143          [-1, 512, 14, 14]               0\n",
            "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-146            [-1, 512, 7, 7]               0\n",
            "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
            "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-151           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-152           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-155            [-1, 512, 7, 7]               0\n",
            "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-158            [-1, 512, 7, 7]               0\n",
            "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-161           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-162           [-1, 2048, 7, 7]               0\n",
            "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
            "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-165            [-1, 512, 7, 7]               0\n",
            "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
            "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
            "            ReLU-168            [-1, 512, 7, 7]               0\n",
            "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
            "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
            "            ReLU-171           [-1, 2048, 7, 7]               0\n",
            "      BottleNeck-172           [-1, 2048, 7, 7]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                   [-1, 10]          20,490\n",
            "================================================================\n",
            "Total params: 23,528,522\n",
            "Trainable params: 23,528,522\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 286.55\n",
            "Params size (MB): 89.75\n",
            "Estimated Total Size (MB): 376.88\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTGsbthX-t7n"
      },
      "source": [
        "model_T weight 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPcZ43YM-tew"
      },
      "source": [
        "model_T.apply(initialize_weights);"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc0uRNEc_fHu"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(model_T.parameters(), lr=0.01)\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=5)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6EMS_Kv-17L"
      },
      "source": [
        "Teacher 학습을 위한 parameter 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3Tg_iu3_NBm"
      },
      "source": [
        "params_train = {\n",
        "    'num_epochs':30,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':trainloader,\n",
        "    'val_dl':testloader,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/teacher_weights.pt',\n",
        "}\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGr60Klx_S0Y",
        "outputId": "a82860d6-5584-402f-d52d-db2375bfc001"
      },
      "source": [
        "model_T, loss_hist, metric_hist = train_val(model_T, params_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 2.536786, val loss: 1.698068, accuracy: 36.14, time: 1.4106 min\n",
            "----------\n",
            "Epoch 1/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.526563, val loss: 1.435364, accuracy: 47.74, time: 2.8245 min\n",
            "----------\n",
            "Epoch 2/29, current lr= 0.01\n",
            "train loss: 1.285924, val loss: 1.436710, accuracy: 54.01, time: 4.2263 min\n",
            "----------\n",
            "Epoch 3/29, current lr= 0.01\n",
            "train loss: 1.101731, val loss: 8.619467, accuracy: 42.13, time: 5.6345 min\n",
            "----------\n",
            "Epoch 4/29, current lr= 0.01\n",
            "train loss: 1.018065, val loss: 1.514079, accuracy: 57.31, time: 7.0376 min\n",
            "----------\n",
            "Epoch 5/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.062391, val loss: 1.187954, accuracy: 59.52, time: 8.4521 min\n",
            "----------\n",
            "Epoch 6/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.921131, val loss: 0.990944, accuracy: 66.58, time: 9.8622 min\n",
            "----------\n",
            "Epoch 7/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.837302, val loss: 0.864153, accuracy: 70.84, time: 11.2730 min\n",
            "----------\n",
            "Epoch 8/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.682823, val loss: 0.829056, accuracy: 71.92, time: 12.6758 min\n",
            "----------\n",
            "Epoch 9/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.619393, val loss: 0.821583, accuracy: 71.54, time: 14.0890 min\n",
            "----------\n",
            "Epoch 10/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.537970, val loss: 0.815377, accuracy: 73.06, time: 15.4936 min\n",
            "----------\n",
            "Epoch 11/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.478447, val loss: 0.811819, accuracy: 73.16, time: 16.9074 min\n",
            "----------\n",
            "Epoch 12/29, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 0.429592, val loss: 0.782404, accuracy: 75.40, time: 18.3193 min\n",
            "----------\n",
            "Epoch 13/29, current lr= 0.01\n",
            "train loss: 0.380155, val loss: 0.879172, accuracy: 73.02, time: 19.7296 min\n",
            "----------\n",
            "Epoch 14/29, current lr= 0.01\n",
            "train loss: 0.323765, val loss: 0.869925, accuracy: 73.88, time: 21.1373 min\n",
            "----------\n",
            "Epoch 15/29, current lr= 0.01\n",
            "train loss: 0.278178, val loss: 0.910003, accuracy: 74.18, time: 22.5494 min\n",
            "----------\n",
            "Epoch 16/29, current lr= 0.01\n",
            "train loss: 0.249436, val loss: 0.974748, accuracy: 73.07, time: 23.9593 min\n",
            "----------\n",
            "Epoch 17/29, current lr= 0.01\n",
            "train loss: 0.216357, val loss: 0.943738, accuracy: 74.29, time: 25.3688 min\n",
            "----------\n",
            "Epoch 18/29, current lr= 0.01\n",
            "Loading best model weights!\n",
            "train loss: 0.194444, val loss: 0.958692, accuracy: 75.59, time: 26.7763 min\n",
            "----------\n",
            "Epoch 19/29, current lr= 0.001\n",
            "train loss: 0.187753, val loss: 0.800775, accuracy: 78.16, time: 28.1875 min\n",
            "----------\n",
            "Epoch 20/29, current lr= 0.001\n",
            "train loss: 0.093268, val loss: 0.906250, accuracy: 78.37, time: 29.6001 min\n",
            "----------\n",
            "Epoch 21/29, current lr= 0.001\n",
            "train loss: 0.047021, val loss: 1.079791, accuracy: 77.69, time: 31.0092 min\n",
            "----------\n",
            "Epoch 22/29, current lr= 0.001\n",
            "train loss: 0.028937, val loss: 1.234420, accuracy: 78.12, time: 32.4180 min\n",
            "----------\n",
            "Epoch 23/29, current lr= 0.001\n",
            "train loss: 0.023768, val loss: 1.332804, accuracy: 77.26, time: 33.8267 min\n",
            "----------\n",
            "Epoch 24/29, current lr= 0.001\n",
            "Loading best model weights!\n",
            "train loss: 0.019053, val loss: 1.398780, accuracy: 77.57, time: 35.2260 min\n",
            "----------\n",
            "Epoch 25/29, current lr= 0.0001\n",
            "Copied best model weights!\n",
            "train loss: 0.238864, val loss: 0.733104, accuracy: 77.35, time: 36.6386 min\n",
            "----------\n",
            "Epoch 26/29, current lr= 0.0001\n",
            "train loss: 0.185951, val loss: 0.750738, accuracy: 78.05, time: 38.0440 min\n",
            "----------\n",
            "Epoch 27/29, current lr= 0.0001\n",
            "train loss: 0.157760, val loss: 0.779195, accuracy: 78.08, time: 39.4479 min\n",
            "----------\n",
            "Epoch 28/29, current lr= 0.0001\n",
            "train loss: 0.132650, val loss: 0.811607, accuracy: 78.32, time: 40.8506 min\n",
            "----------\n",
            "Epoch 29/29, current lr= 0.0001\n",
            "train loss: 0.114471, val loss: 0.848039, accuracy: 78.29, time: 42.2591 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h3eRqkuBCod"
      },
      "source": [
        "1. 가중치 초기화_BaseLine check를 위해 사용했던 model_S(Student)의 weight 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj93Fy0R-P2j"
      },
      "source": [
        "model_S.apply(initialize_weights);"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3yLTQt-BTmL"
      },
      "source": [
        "2. Teacher model학습을 통해 얻은 Weight값(Soft Label들을 Load)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4LXd8wCBbF-"
      },
      "source": [
        "# load weight\n",
        "model_T.load_state_dict(torch.load('/content/models/teacher_weights.pt'))\n",
        "\n",
        "# optimizer\n",
        "opt = optim.Adam(model_S.parameters())"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xH6DZPTBoNU"
      },
      "source": [
        "3. KD 함수 선언 및 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQks09bEBstX"
      },
      "source": [
        "# knowledge distillation loss\n",
        "def distillation(y, labels, teacher_scores, T, alpha):\n",
        "    # distillation loss + classification loss\n",
        "    # y: student\n",
        "    # labels: hard label\n",
        "    # teacher_scores: soft label\n",
        "    return nn.KLDivLoss()(F.log_softmax(y/T), F.softmax(teacher_scores/T)) * (T*T * 2.0 + alpha) + F.cross_entropy(y,labels) * (1.-alpha)\n",
        "\n",
        "# val loss\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z6bqoKKB31k"
      },
      "source": [
        "def distill_loss_batch(output, target, teacher_output, loss_fn=distillation, opt=opt):\n",
        "    loss_b = loss_fn(output, target, teacher_output, T=20.0, alpha=0.7)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "\n",
        "    return loss_b.item(), metric_b"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpjJ6rlpB6jP"
      },
      "source": [
        "4. 30 epoch로 학습시도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSNbL344B90W",
        "outputId": "2f1195da-f7f9-4be1-9ec7-95ae0e161013"
      },
      "source": [
        "num_epochs= 30\n",
        "\n",
        "loss_history = {'train': [], 'val': []}\n",
        "metric_history = {'train': [], 'val': []}\n",
        "\n",
        "best_loss = float('inf')\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    current_lr = get_lr(opt)\n",
        "    print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "    # train\n",
        "    model_S.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(trainloader.dataset)\n",
        "\n",
        "    for xb, yb in trainloader:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "\n",
        "        output = model_S(xb)\n",
        "        teacher_output = model_T(xb).detach()\n",
        "        loss_b, metric_b = distill_loss_batch(output, yb, teacher_output, loss_fn=distillation, opt=opt)\n",
        "        running_loss += loss_b\n",
        "        running_metric_b = metric_b\n",
        "    train_loss = running_loss / len_data\n",
        "    train_metric = running_metric / len_data\n",
        "\n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # validation\n",
        "    model_S.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss, val_metric = loss_epoch(model_S, loss_func, testloader)\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "\n",
        "    lr_scheduler.step(val_loss)\n",
        "\n",
        "    print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "    print('-'*10)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/29, current lr= 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2748: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.003522, val loss: 0.005662, accuracy: 77.75, time: 1.0239 min\n",
            "----------\n",
            "Epoch 1/29, current lr= 0.001\n",
            "train loss: 0.002107, val loss: 0.005648, accuracy: 78.25, time: 2.0539 min\n",
            "----------\n",
            "Epoch 2/29, current lr= 0.001\n",
            "train loss: 0.001754, val loss: 0.005620, accuracy: 78.78, time: 3.0867 min\n",
            "----------\n",
            "Epoch 3/29, current lr= 0.001\n",
            "train loss: 0.001556, val loss: 0.005687, accuracy: 78.54, time: 4.1175 min\n",
            "----------\n",
            "Epoch 4/29, current lr= 0.001\n",
            "train loss: 0.001383, val loss: 0.005867, accuracy: 78.19, time: 5.1435 min\n",
            "----------\n",
            "Epoch 5/29, current lr= 0.001\n",
            "train loss: 0.001243, val loss: 0.005873, accuracy: 78.51, time: 6.1769 min\n",
            "----------\n",
            "Epoch 6/29, current lr= 0.001\n",
            "train loss: 0.001140, val loss: 0.005983, accuracy: 78.34, time: 7.2092 min\n",
            "----------\n",
            "Epoch 7/29, current lr= 0.001\n",
            "train loss: 0.001094, val loss: 0.005931, accuracy: 78.43, time: 8.2456 min\n",
            "----------\n",
            "Epoch 8/29, current lr= 0.001\n",
            "train loss: 0.001006, val loss: 0.005966, accuracy: 78.38, time: 9.2765 min\n",
            "----------\n",
            "Epoch 9/29, current lr= 0.001\n",
            "train loss: 0.000942, val loss: 0.006050, accuracy: 78.50, time: 10.3114 min\n",
            "----------\n",
            "Epoch 10/29, current lr= 0.001\n",
            "train loss: 0.000902, val loss: 0.006026, accuracy: 78.44, time: 11.3365 min\n",
            "----------\n",
            "Epoch 11/29, current lr= 0.001\n",
            "train loss: 0.000863, val loss: 0.006070, accuracy: 78.40, time: 12.3706 min\n",
            "----------\n",
            "Epoch 12/29, current lr= 0.001\n",
            "train loss: 0.000806, val loss: 0.006071, accuracy: 78.56, time: 13.4026 min\n",
            "----------\n",
            "Epoch 13/29, current lr= 0.001\n",
            "train loss: 0.000773, val loss: 0.006030, accuracy: 78.49, time: 14.4324 min\n",
            "----------\n",
            "Epoch 14/29, current lr= 0.001\n",
            "train loss: 0.000754, val loss: 0.006076, accuracy: 78.33, time: 15.4628 min\n",
            "----------\n",
            "Epoch 15/29, current lr= 0.001\n",
            "train loss: 0.000725, val loss: 0.006029, accuracy: 78.42, time: 16.4869 min\n",
            "----------\n",
            "Epoch 16/29, current lr= 0.001\n",
            "train loss: 0.000695, val loss: 0.005975, accuracy: 78.38, time: 17.5186 min\n",
            "----------\n",
            "Epoch 17/29, current lr= 0.001\n",
            "train loss: 0.000656, val loss: 0.005974, accuracy: 79.03, time: 18.5530 min\n",
            "----------\n",
            "Epoch 18/29, current lr= 0.001\n",
            "train loss: 0.000645, val loss: 0.005981, accuracy: 78.57, time: 19.5829 min\n",
            "----------\n",
            "Epoch 19/29, current lr= 0.001\n",
            "train loss: 0.000622, val loss: 0.006022, accuracy: 78.76, time: 20.6072 min\n",
            "----------\n",
            "Epoch 20/29, current lr= 0.001\n",
            "train loss: 0.000606, val loss: 0.006093, accuracy: 78.68, time: 21.6338 min\n",
            "----------\n",
            "Epoch 21/29, current lr= 0.001\n",
            "train loss: 0.000587, val loss: 0.006043, accuracy: 78.74, time: 22.6696 min\n",
            "----------\n",
            "Epoch 22/29, current lr= 0.001\n",
            "train loss: 0.000566, val loss: 0.006121, accuracy: 78.52, time: 23.6987 min\n",
            "----------\n",
            "Epoch 23/29, current lr= 0.001\n",
            "train loss: 0.000544, val loss: 0.006025, accuracy: 78.51, time: 24.7262 min\n",
            "----------\n",
            "Epoch 24/29, current lr= 0.001\n",
            "train loss: 0.000527, val loss: 0.006041, accuracy: 78.63, time: 25.7489 min\n",
            "----------\n",
            "Epoch 25/29, current lr= 0.001\n",
            "train loss: 0.000516, val loss: 0.006040, accuracy: 78.43, time: 26.7785 min\n",
            "----------\n",
            "Epoch 26/29, current lr= 0.001\n",
            "train loss: 0.000505, val loss: 0.006130, accuracy: 78.13, time: 27.8152 min\n",
            "----------\n",
            "Epoch 27/29, current lr= 0.001\n",
            "train loss: 0.000487, val loss: 0.006067, accuracy: 78.26, time: 28.8464 min\n",
            "----------\n",
            "Epoch 28/29, current lr= 0.001\n",
            "train loss: 0.000465, val loss: 0.006071, accuracy: 78.74, time: 29.8718 min\n",
            "----------\n",
            "Epoch 29/29, current lr= 0.001\n",
            "train loss: 0.000465, val loss: 0.006076, accuracy: 78.42, time: 30.9057 min\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVIjdRvh67BF"
      },
      "source": [
        "Reference\n",
        "1. https://sanghyu.tistory.com/113"
      ]
    }
  ]
}